{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch>=2.1.0 in /home/jnw/.local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.16.0 in /home/jnw/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.21.0)\n",
      "Requirement already satisfied: scikit-learn>=1.2.2 in /home/jnw/.local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.6.1)\n",
      "Requirement already satisfied: biopython>=1.81 in /home/jnw/.local/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.85)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /home/jnw/.local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /home/jnw/.local/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /home/jnw/.local/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.15.2)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /home/jnw/.local/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (3.10.1)\n",
      "Requirement already satisfied: seaborn>=0.12.0 in /home/jnw/.local/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.13.2)\n",
      "Requirement already satisfied: ipython>=8.0.0 in /home/jnw/.local/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (8.33.0)\n",
      "Requirement already satisfied: biotite in /home/jnw/.local/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (0.41.2)\n",
      "Requirement already satisfied: esm in /home/jnw/.local/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (3.1.6)\n",
      "Requirement already satisfied: transformers in /home/jnw/.local/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (4.48.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: networkx in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: fsspec in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (12.4.5.8)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (3.6.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/jnw/.local/lib/python3.10/site-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (12.3.1.170)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jnw/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.1.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/jnw/.local/lib/python3.10/site-packages (from torchvision>=0.16.0->-r requirements.txt (line 2)) (11.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/jnw/.local/lib/python3.10/site-packages (from scikit-learn>=1.2.2->-r requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/jnw/.local/lib/python3.10/site-packages (from scikit-learn>=1.2.2->-r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jnw/.local/lib/python3.10/site-packages (from pandas>=2.0.0->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jnw/.local/lib/python3.10/site-packages (from pandas>=2.0.0->-r requirements.txt (line 6)) (2025.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 6)) (2022.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jnw/.local/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jnw/.local/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 8)) (4.56.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jnw/.local/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 8)) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 8)) (2.4.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jnw/.local/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 8)) (1.3.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/jnw/.local/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 8)) (1.4.8)\n",
      "Requirement already satisfied: exceptiongroup in /home/jnw/.local/lib/python3.10/site-packages (from ipython>=8.0.0->-r requirements.txt (line 10)) (1.2.2)\n",
      "Requirement already satisfied: decorator in /home/jnw/.local/lib/python3.10/site-packages (from ipython>=8.0.0->-r requirements.txt (line 10)) (5.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/jnw/.local/lib/python3.10/site-packages (from ipython>=8.0.0->-r requirements.txt (line 10)) (3.0.50)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/jnw/.local/lib/python3.10/site-packages (from ipython>=8.0.0->-r requirements.txt (line 10)) (5.14.3)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/jnw/.local/lib/python3.10/site-packages (from ipython>=8.0.0->-r requirements.txt (line 10)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/jnw/.local/lib/python3.10/site-packages (from ipython>=8.0.0->-r requirements.txt (line 10)) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/lib/python3/dist-packages (from ipython>=8.0.0->-r requirements.txt (line 10)) (4.8.0)\n",
      "Requirement already satisfied: stack_data in /home/jnw/.local/lib/python3.10/site-packages (from ipython>=8.0.0->-r requirements.txt (line 10)) (0.6.3)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/jnw/.local/lib/python3.10/site-packages (from ipython>=8.0.0->-r requirements.txt (line 10)) (2.19.1)\n",
      "Requirement already satisfied: msgpack>=0.5.6 in /home/jnw/.local/lib/python3.10/site-packages (from biotite->-r requirements.txt (line 11)) (1.1.0)\n",
      "Requirement already satisfied: requests>=2.12 in /usr/lib/python3/dist-packages (from biotite->-r requirements.txt (line 11)) (2.25.1)\n",
      "Requirement already satisfied: attrs in /usr/lib/python3/dist-packages (from esm->-r requirements.txt (line 12)) (21.2.0)\n",
      "Requirement already satisfied: msgpack-numpy in /home/jnw/.local/lib/python3.10/site-packages (from esm->-r requirements.txt (line 12)) (0.4.8)\n",
      "Requirement already satisfied: brotli in /home/jnw/.local/lib/python3.10/site-packages (from esm->-r requirements.txt (line 12)) (1.1.0)\n",
      "Requirement already satisfied: cloudpathlib in /home/jnw/.local/lib/python3.10/site-packages (from esm->-r requirements.txt (line 12)) (0.21.0)\n",
      "Requirement already satisfied: zstd in /home/jnw/.local/lib/python3.10/site-packages (from esm->-r requirements.txt (line 12)) (1.5.6.6)\n",
      "Requirement already satisfied: tenacity in /home/jnw/.local/lib/python3.10/site-packages (from esm->-r requirements.txt (line 12)) (9.0.0)\n",
      "Requirement already satisfied: einops in /home/jnw/.local/lib/python3.10/site-packages (from esm->-r requirements.txt (line 12)) (0.8.1)\n",
      "Requirement already satisfied: torchtext in /home/jnw/.local/lib/python3.10/site-packages (from esm->-r requirements.txt (line 12)) (0.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers->-r requirements.txt (line 13)) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/jnw/.local/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 13)) (0.29.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jnw/.local/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 13)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/jnw/.local/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 13)) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jnw/.local/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 13)) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jnw/.local/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 13)) (4.67.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/jnw/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=8.0.0->-r requirements.txt (line 10)) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in /usr/lib/python3/dist-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=8.0.0->-r requirements.txt (line 10)) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/jnw/.local/lib/python3.10/site-packages (from stack_data->ipython>=8.0.0->-r requirements.txt (line 10)) (2.2.0)\n",
      "Requirement already satisfied: pure-eval in /home/jnw/.local/lib/python3.10/site-packages (from stack_data->ipython>=8.0.0->-r requirements.txt (line 10)) (0.2.3)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/jnw/.local/lib/python3.10/site-packages (from stack_data->ipython>=8.0.0->-r requirements.txt (line 10)) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import h5py\n",
    "import tqdm\n",
    "import math\n",
    "import gc # Garbage collector\n",
    "import os # For creating directories\n",
    "import json # For saving results\n",
    "import time # For timestamping runs\n",
    "import random # For seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # For Swish if needed\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.utils.tensorboard import SummaryWriter # For TensorBoard\n",
    "\n",
    "from sklearn.model_selection import KFold, ParameterSampler # For CV and Random Search\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Our Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in data from HDF5 files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding_retriever(Dataset): \n",
    "    def __init__(self, h5_path, protein_keys = None):\n",
    "        self.h5_path = h5_path\n",
    "        with h5py.File(self.h5_path, 'r') as f:\n",
    "            all_keys = list(f['embeddings_folder'].keys())\n",
    "            all_keys.sort()\n",
    "            self.protein_keys = protein_keys if protein_keys is not None else all_keys\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.protein_keys) \n",
    "\n",
    "    def __getitem__(self, index): \n",
    "        protein_key = self.protein_keys[index]\n",
    "        with h5py.File(self.h5_path, 'r') as f:\n",
    "            protein_group = f['embeddings_folder'][protein_key]\n",
    "            embeddings = protein_group['embeddings'][:]\n",
    "            labels = protein_group['labels'][:]\n",
    "            labels = labels.astype(np.float32) \n",
    "\n",
    "        return {\n",
    "            'name': protein_key,\n",
    "            'embeddings': torch.tensor(embeddings, dtype=torch.float32),\n",
    "            'labels': torch.tensor(labels, dtype=torch.float32),\n",
    "            'length': len(labels) \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '3b9k_B',\n",
       " 'embeddings': tensor([[-0.0792, -0.0822,  0.0584,  ..., -0.0358,  0.2468,  0.0965],\n",
       "         [ 0.2719,  0.1316, -0.1275,  ..., -0.0662,  0.0838,  0.0270],\n",
       "         [ 0.0752, -0.1247, -0.3128,  ..., -0.3670, -0.0709, -0.1302],\n",
       "         ...,\n",
       "         [-0.0930,  0.1506,  0.3534,  ..., -0.0738, -0.3277, -0.1105],\n",
       "         [ 0.0638,  0.1243,  0.2399,  ..., -0.2450, -0.2691,  0.0887],\n",
       "         [ 0.0787, -0.0101,  0.3330,  ..., -0.0309, -0.1629,  0.1119]]),\n",
       " 'labels': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'length': 117}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## testing that we can retrieve specified protein from HDF5\n",
    "protein_data = Embedding_retriever('/work/jgg/exp1137-improving-b-cell-antigen-predictions-using-plms/esm2_protein_embeddings.h5', ['3b9k_B'])\n",
    "protein_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "BlockingIOError",
     "evalue": "[Errno 11] Unable to synchronously open file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBlockingIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m protein_data_esmc \u001b[38;5;241m=\u001b[39m \u001b[43mEmbedding_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/work/jgg/exp1137-improving-b-cell-antigen-predictions-using-plms/esmc_protein_embeddings.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m5ggv_Y\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m protein_data_esmc[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m, in \u001b[0;36mEmbedding_retriever.__init__\u001b[0;34m(self, h5_path, protein_keys)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, h5_path, protein_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh5_path \u001b[38;5;241m=\u001b[39m h5_path\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh5_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m         all_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings_folder\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      6\u001b[0m         all_keys\u001b[38;5;241m.\u001b[39msort()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:564\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    555\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    556\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    557\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    558\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    559\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    560\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    561\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    562\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    563\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 564\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:238\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    237\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 238\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    240\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mBlockingIOError\u001b[0m: [Errno 11] Unable to synchronously open file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')"
     ]
    }
   ],
   "source": [
    "protein_data_esmc = Embedding_retriever('/work/jgg/exp1137-improving-b-cell-antigen-predictions-using-plms/esmc_protein_embeddings.h5', ['5ggv_Y'])\n",
    "protein_data_esmc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "BlockingIOError",
     "evalue": "[Errno 11] Unable to synchronously open file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBlockingIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprotein_data_esmc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m, in \u001b[0;36mEmbedding_retriever.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index): \n\u001b[1;32m     13\u001b[0m     protein_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprotein_keys[index]\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh5_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     15\u001b[0m         protein_group \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings_folder\u001b[39m\u001b[38;5;124m'\u001b[39m][protein_key]\n\u001b[1;32m     16\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m protein_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m][:]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:564\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    555\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    556\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    557\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    558\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    559\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    560\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    561\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    562\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    563\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 564\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:238\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    237\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 238\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    240\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mBlockingIOError\u001b[0m: [Errno 11] Unable to synchronously open file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')"
     ]
    }
   ],
   "source": [
    "print(protein_data_esmc[0]['embeddings'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '7lj4_B',\n",
       " 'embeddings': tensor([[ 0.0967,  0.0548, -0.0380,  ...,  0.3126,  0.1504, -0.0625],\n",
       "         [-0.0258, -0.1512,  0.0948,  ...,  0.2948, -0.0251, -0.0958],\n",
       "         [-0.0322, -0.0087, -0.1973,  ...,  0.2294, -0.1310, -0.1817],\n",
       "         ...,\n",
       "         [-0.2181, -0.1279, -0.0083,  ...,  0.0957, -0.0185,  0.0791],\n",
       "         [-0.2594, -0.0837,  0.0623,  ...,  0.0057, -0.0654, -0.1096],\n",
       "         [-0.0031,  0.1199,  0.1547,  ...,  0.0080, -0.1935, -0.0970]]),\n",
       " 'labels': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.]),\n",
       " 'length': 289}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = Embedding_retriever('/work/jgg/exp1137-improving-b-cell-antigen-predictions-using-plms/esm2_test_protein_embeddings.h5', ['7lj4_B'])\n",
    "test_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    embeddings = [item['embeddings'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "    lengths = [item['length'] for item in batch]\n",
    "    names = [item['name'] for item in batch]\n",
    "\n",
    "    padded_embeddings = nn.utils.rnn.pad_sequence(embeddings, batch_first=True, padding_value= 0.0)\n",
    "    padded_labels = nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-1)\n",
    "\n",
    "    max_len = padded_embeddings.size(1)\n",
    "    lengths_tensor = torch.tensor(lengths, dtype=torch.long)\n",
    "    padding_mask  =torch.arange(max_len)[None, :] >= lengths_tensor[:, None]\n",
    "\n",
    "    return {\n",
    "        'names': names,\n",
    "        'embeddings': padded_embeddings,\n",
    "        'labels': padded_labels,\n",
    "        'padding_mask': padding_mask,\n",
    "        'lengths': lengths_tensor\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Our Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEMO MLP MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_size_esm2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m----> 2\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(\u001b[43membedding_size_esm2\u001b[49m, \u001b[38;5;241m128\u001b[39m),\n\u001b[1;32m      3\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m      4\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[1;32m      5\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m      6\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSigmoid()\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m     10\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCELoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Remove the space\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_size_esm2' is not defined"
     ]
    }
   ],
   "source": [
    "cls = torch.nn.Sequential(\n",
    "    torch.nn.Linear(embedding_size_esm2, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(128, 1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(cls.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.BCELoss(reduction='none')  # Remove the space\n",
    "\n",
    "first_10_items = list(preprocessed_data.items())[:10]\n",
    "\n",
    "for epoch in range(5):\n",
    "    total_loss = 0  # Initialize the loss counter\n",
    "    \n",
    "    # Extract sequences and labels first\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for name, obs in first_10_items:\n",
    "        sequences.append(obs['sequence'])\n",
    "        labels.append(obs['labels'])\n",
    "    \n",
    "    # Now train on each sequence\n",
    "    for i in range(len(sequences)):\n",
    "        sequence = sequences[i]\n",
    "        label = labels[i]\n",
    "        \n",
    "        inputs = tokenizer_650m(sequence, return_tensors=\"pt\")  # Remove **\n",
    "        with torch.no_grad():\n",
    "            esm_output = model_650m(**inputs)\n",
    "        embeddings = esm_output.last_hidden_state\n",
    "\n",
    "        seq_len = len(sequence)\n",
    "\n",
    "        predictions = cls(embeddings[0, 1:seq_len+1])\n",
    "        predictions = predictions.squeeze(-1)\n",
    "\n",
    "        target = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        loss = loss_fn(predictions, target)\n",
    "        mean_loss = loss.mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        mean_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += mean_loss.item()\n",
    "\n",
    "    print(f\"epoch {epoch+1}, loss: {total_loss/len(sequences):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_epitopes(sequence, model, tokenizer, esm_model):\n",
    "    # Tokenize sequence\n",
    "    inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "    \n",
    "    # Get ESM embeddings\n",
    "    with torch.no_grad():\n",
    "        esm_output = esm_model(**inputs)\n",
    "    embeddings = esm_output.last_hidden_state\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model(embeddings[0, 1:len(sequence)+1]).squeeze(-1)\n",
    "    \n",
    "    # Convert to probabilities\n",
    "    probs = predictions.detach().numpy()\n",
    "    \n",
    "    # Convert to binary predictions\n",
    "    binary_preds = (probs > 0.2).astype(int)\n",
    "    \n",
    "    return probs, binary_preds\n",
    "\n",
    "# Example usage\n",
    "test_seq = preprocessed_data['7rk1_A']['sequence']\n",
    "probs, binary_preds = predict_epitopes(test_seq, cls, tokenizer_650m, model_650m)\n",
    "\n",
    "# Visualize predictions compared to actual labels\n",
    "actual_labels = preprocessed_data['7rk1_A']['labels']\n",
    "print(f\"Sequence length: {len(test_seq)}\")\n",
    "print(f\"outpur {binary_preds}\" )\n",
    "print(f\"Predicted epitope positions: {[i for i, p in enumerate(binary_preds) if p == 1]}\")\n",
    "print(f\"Actual epitope positions: {[i for i, l in enumerate(actual_labels) if l == 1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def plot_epitope_probabilities(probs, actual_labels=None, sequence=None, threshold=0.5):\n",
    "    positions = np.arange(1, len(probs) + 1)\n",
    "    \n",
    "    # Create a colormap for probabilities\n",
    "    cmap = plt.cm.get_cmap('RdYlGn_r')\n",
    "    colors = [cmap(p) for p in probs]\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    bars = plt.bar(positions, probs, color=colors, width=0.8, alpha=0.7)\n",
    "    \n",
    "    # Add threshold line\n",
    "    plt.axhline(y=threshold, color='black', linestyle='--', alpha=0.7, label=f'Threshold ({threshold})')\n",
    "    \n",
    "    # Add actual epitope labels if provided\n",
    "    if actual_labels is not None:\n",
    "        for i, label in enumerate(actual_labels):\n",
    "            if label == 1:\n",
    "                plt.axvspan(i+0.5, i+1.5, color='blue', alpha=0.2)\n",
    "    \n",
    "    # Set x-axis ticks to show position numbers\n",
    "    if len(positions) > 50:\n",
    "        # For longer sequences, show every 10th position\n",
    "        plt.xticks(positions[::10], positions[::10])\n",
    "    else:\n",
    "        # For shorter sequences, show all positions\n",
    "        plt.xticks(positions, positions)\n",
    "    \n",
    "    # Add colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(0, 1))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm)\n",
    "    cbar.set_label('Probability of being an epitope')\n",
    "    \n",
    "    plt.xlabel('Amino Acid Position')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Epitope Prediction Probabilities')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt.gcf()\n",
    "\n",
    "# Example usage\n",
    "test_seq = preprocessed_data['7rk1_A']['sequence']\n",
    "actual_labels = preprocessed_data['7rk1_A']['labels']\n",
    "probs, _ = predict_epitopes(test_seq, cls, tokenizer_650m, model_650m)\n",
    "\n",
    "# Plot the first 100 positions for better visibility\n",
    "plot_window = 100\n",
    "plot_epitope_probabilities(\n",
    "    probs[:plot_window], \n",
    "    actual_labels[:plot_window], \n",
    "    test_seq[:plot_window],\n",
    "    threshold=0.3\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Positional Encoding --- \n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len = MAX_LEN):\n",
    "        super().__init__()\n",
    "            #super(PositionalEncoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        pe = torch.zeros(max_len, d_model) #generating empty tensor to later populate with positional encoding values.\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1) # Create a column vector of token positions, which will later be used to calculate sinusoidal encodings \n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # the denominator of PE formula.\n",
    "\n",
    "        #Slicing of both even and uneven terms (removed if/else function)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) # generators tensor using sine function\n",
    "        pe[:, 1::2] = torch.cos(position * div_term) # generators tensor using sine function\n",
    "\n",
    "        self.register_buffer('pe', pe) # fixed paramter, not trainable.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # apply positional encoding to input.\n",
    "        x = x + self.pe[:x.size(1), :] # slicing ensures correct dimension and adds positional encoding to input.\n",
    "        return self.dropout(x) # regularization to input\n",
    "    \n",
    "        # OBS!!!: dimension output of PE is now [batch_size, seq_len, embed_dim]\n",
    "\n",
    "# --- SiLu (Swish) Feed Forward Network ---\n",
    "class SiLuFFN(nn.Module):\n",
    "    def __init__(self, embed_dim, ffn_hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.w1 = nn.Linear(embed_dim, ffn_hidden_dim, bias=True) # defines 1st layer\n",
    "        self.w2 = nn.Linear(ffn_hidden_dim, embed_dim, bias=True) # defines 2nd layer\n",
    "        self.dropout = nn.Dropout(dropout) # a good ol' dropout layer\n",
    "        self.activation = F.silu # stores SWISH activation function\n",
    "\n",
    "    def forward(self ,x):\n",
    "        hidden = self.w1(x) #passing input through first (w1) layer    \n",
    "        activated = self.activation(hidden) # applying SWISH    \n",
    "        dropped = self.dropout(activated) # applying dropout\n",
    "        output = self.w2(dropped) # pass through second (w2) layer\n",
    "\n",
    "        return output # returns final processed tensor\n",
    "\n",
    "\n",
    "# --- Transformer Encoder Layer with SiLU FFN ---\n",
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, embed_dim, nhead, ffn_hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        #Sub layers\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim, nhead, dropout=dropout, batch_first=True) # 1. MHA\n",
    "        self.ffn = SiLuFFN(embed_dim, ffn_hidden_dim, dropout) # FFN part of transformer block.T_destination\n",
    "\n",
    "        # Layer norm & dropout\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim) # will have different weights\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout) # will have different weights\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        # MHA applied in encoder\n",
    "        attention_output, _ = self.self_attn(src, src, src, # these are for the Q, K and V tensors\n",
    "                                             attn_mask=src_mask,\n",
    "                                             key_padding_mask=src_key_padding_mask,\n",
    "                                             need_weights=False)\n",
    "        \n",
    "        # Add & Norm (Residual Connection 1) \n",
    "        src = src + self.dropout1(attention_output) # We dropout some of our output from the attention layer\n",
    "        src = self.norm1(src) # and we apply layer normalization\n",
    "        \n",
    "        # FF block\n",
    "        ffn_output = self.ffn(src)\n",
    "\n",
    "        # Add & Norm (Residual Connection 2) \n",
    "        src = src + self.dropout2(ffn_output) # We dropout some of our output from the FFN layer\n",
    "        src = self.norm2(src) # and we apply layer normalization\n",
    "\n",
    "        return src # this output goes to decoder block\n",
    "    \n",
    "\n",
    "\n",
    "# --- Main Epitope Transformer Model using SiLU ---\n",
    "class EpitopeTransformer(nn.Module):\n",
    "    def __init__(self, embed_dim, nhead, num_encoder_layers, ffn_hidden_dim,\n",
    "                 dropout=0.1, max_len=MAX_LEN):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.pos_encoder = PositionalEncoder(embed_dim, dropout, max_len) # first PE layer\n",
    "\n",
    "        # Encoder Stack\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerEncoderLayer(embed_dim, nhead, ffn_hidden_dim, dropout)\n",
    "            for _ in range(num_encoder_layers)\n",
    "        ])\n",
    "\n",
    "        self.norm_final = nn.LayerNorm(embed_dim) # normalized before added to next encoder layer. \n",
    "        self.output_layer = nn.Linear(embed_dim, 1) # transformed to 1 dimension\n",
    "        self.init_weights() # optional, but good practice\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.output_layer.bias.data.zero_()\n",
    "        self.output_layer.bias.data.uniform_(-initrange, initrange) #we initialize between -0.1 to 0.1. Biased to be 0\n",
    "\n",
    "    def forward(self, src, src_key_padding_mask=None): #padding mask=None as we're only in encoder layer\n",
    "        src = self.pos_encoder(src) # we encode input\n",
    "\n",
    "        output = src # we initialize output value and loop through each encoder layer passing the output from layer to layer.\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, src_key_padding_mask=src_key_padding_mask)\n",
    "        output = self.norm_final(output) # apply final norm\n",
    "        output_logits = self.output_layer(output) # Apply the final output layer (Prediction Head)\n",
    "        # Output shape: [batch_size, seq_len, 1]\n",
    "        \n",
    "        return output_logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Function ---\n",
    "def train_epoch(model, dataloader, optimizer, criterion, device, epoch, writer=None):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = len(dataloader)\n",
    "    progress_bar = tqdm.tqdm(dataloader, desc=f'Epoch {epoch+1} Training', leave=False, ncols=100)\n",
    "    for i, batch in enumerate(progress_bar):\n",
    "        embeddings = batch['embeddings'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        padding_mask = batch['padding_mask'].to(device)\n",
    "        optimizer.zero_grad() # resets gradiants from prev batch\n",
    "        outputs = model(embeddings, src_key_padding_mask=padding_mask)\n",
    "        outputs = outputs.squeeze(-1)\n",
    "        active_mask = (labels != -1)\n",
    "        if active_mask.sum() == 0: continue\n",
    "        active_logits = outputs[active_mask]\n",
    "        active_labels = labels[active_mask]\n",
    "        loss = criterion(active_logits, active_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "    if writer: writer.add_scalar('Loss/train_epoch', avg_loss, epoch) # Log average epoch loss\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "# --- Evaluation Function ---      \n",
    "def evaluate(model, dataloader, criterion, device, epoch, writer=None):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds_prob = []\n",
    "    all_labels_list = []\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm.tqdm(dataloader, desc=f\"Epoch {epoch+1} Evaluating\", leave=False, ncols=100)\n",
    "        for batch in progress_bar:\n",
    "            embeddings = batch['embeddings'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            padding_mask = batch['padding_mask'].to(device)\n",
    "            outputs = model(embeddings,src_key_padding_mask=padding_mask).squeeze(-1)\n",
    "            active_mask = (labels != -1)\n",
    "            if active_mask.sum() == 0: continue\n",
    "            active_logits = outputs[active_mask]\n",
    "            active_labels = labels[active_mask]\n",
    "            loss = criterion(active_logits, active_labels)\n",
    "            total_loss += loss.item()\n",
    "            probs = torch.sigmoid(active_logits).cpu().numpy() # SIGMOID??? CPU???\n",
    "            all_preds_prob.extend(probs)\n",
    "            all_labels_list.extend(active_labels.cpu().numpy())\n",
    "        \n",
    "    avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "    precision, recall, f1, auc_roc, auc_pr, auc10 = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    if len(all_labels_list) > 0:\n",
    "        all_labels_np = np.array(all_labels_list)\n",
    "        all_preds_prob_np = np.array(all_preds_prob)\n",
    "        if len(np.unique(all_labels_np)) < 2:\n",
    "            print(\"Warning: Only one class present in validation fold/batch.\")\n",
    "            all_preds_binary = (all_preds_prob_np >= 0.5).astype(int)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(all_labels_np, all_preds_binary, average='binary', zero_division=0)\n",
    "            auc_roc = 0.0\n",
    "            auc10 = 0.0\n",
    "            try:\n",
    "                auc_pr = average_precision_score(all_labels_np, all_preds_prob_np)\n",
    "            except ValueError:\n",
    "                auc_pr = 0.0\n",
    "        else:\n",
    "            all_preds_binary = (all_preds_prob_np >= 0.5).astype(int)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(all_labels_np, all_preds_binary, average='binary', zero_division=0)\n",
    "            auc_pr = average_precision_score(all_labels_np, all_preds_prob_np) # den her var lidt mystisk\n",
    "            try:\n",
    "                auc_roc = roc_auc_score(all_labels_np, all_preds_prob_np)\n",
    "                auc10 = roc_auc_score(all_labels_np, all_preds_prob_np, max_fpr=0.1)\n",
    "            except ValueError:\n",
    "                print(\"Warning: ValueError during AUC calculation despite unqie check.\")\n",
    "                auc_roc = 0.0\n",
    "                auc10 = 0.0\n",
    "\n",
    "    print(f\"Eval Loss: {avg_loss:.4f}, F1: {f1:.4f}, AUC-PR: {auc_pr:.4f}, AUC-ROC: {auc_roc:.4f}, AUC10: {auc10:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "\n",
    "    if writer:\n",
    "        writer.add_scalar('Loss/val', avg_loss, epoch)\n",
    "        writer.add_scalar('Metrics/F1', f1, epoch)\n",
    "        writer.add_scalar('Metrics/AUC-PR', auc_pr, epoch)\n",
    "        writer.add_scalar('Metrics/AUC-ROC', auc_roc, epoch)\n",
    "        writer.add_scalar('Metrics/AUC10', auc10, epoch)\n",
    "        writer.add_scalar('Metrics/Precision', precision, epoch)\n",
    "        writer.add_scalar('Metrics/Recall', recall, epoch)\n",
    "    return avg_loss, precision, recall, f1, auc_roc, auc_pr, auc10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m EMBED_DIM \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membed_dim\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     25\u001b[0m BASE_RUNS_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_runs\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#overall base dir\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m RUN_TYPE_DIR \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_RUNS_DIR, EMBEDDING_TYPE) \u001b[38;5;66;03m# subfolder in dir\u001b[39;00m\n\u001b[1;32m     27\u001b[0m MODEL_SAVE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(RUN_TYPE_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved models\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#subfolder with saved models\u001b[39;00m\n\u001b[1;32m     28\u001b[0m TENSORBOARD_BASE_DIR \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(RUN_TYPE_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "\n",
    "# EMBEDDING TYPE\n",
    "EMBEDDING_TYPE = 'esm2' \n",
    "\n",
    "\n",
    "# MAPPING\n",
    "EMBEDDING_CONFIG = {\n",
    "    'esm2': {\n",
    "        'h5_path': 'esm2_protein_embeddings.h5',\n",
    "        'embed_dim': 1280\n",
    "    },\n",
    "    'esmc': {\n",
    "        'h5_path': 'esmc_protein_embeddings.h5',\n",
    "        'embed_dim': 960\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# PATHS AND DATA\n",
    "config = EMBEDDING_CONFIG[EMBEDDING_TYPE]\n",
    "H5_FILE_PATH = config['h5_path']\n",
    "EMBED_DIM = config['embed_dim']\n",
    "\n",
    "BASE_RUNS_DIR = 'transformer_runs' #overall base dir\n",
    "RUN_TYPE_DIR = os.path.join(BASE_RUNS_DIR, EMBEDDING_TYPE) # subfolder in dir\n",
    "MODEL_SAVE_DIR = os.path.join(RUN_TYPE_DIR, 'saved models') #subfolder with saved models\n",
    "TENSORBOARD_BASE_DIR = os.path.join(RUN_TYPE_DIR, 'tensorboard')\n",
    "RESULTS_FILE = os.path.join(RUN_TYPE_DIR, f'{EMBEDDING_TYPE}_hyperparam_search_results.json')\n",
    "\n",
    "\n",
    "# Fixed Training Settings\n",
    "N_SPLITS = 5 # number of K-Fold splits\n",
    "N_EPOCHS = 10 # Max epochs per fold\n",
    "BATCH_SIZE = 8 # !!!maybe adjust for GPU memory!!!!\n",
    "RANDOM_SEED = 17 #bc 17 is a cool number 8-)\n",
    "\n",
    "\n",
    "# Model Architecture Base (Embed dim now comes from config)\n",
    "MAX_LEN = 5000 # max seq len for positional encoding # can be changed\n",
    "\n",
    "\n",
    "# --- Random Search Space ---\n",
    "param_dist = {\n",
    "    'learning_rate': [1e-5, 5e-5, 1e-4, 5e-4], # !!!! come back to this\n",
    "    'dropout': [0.1, 0.15, 0.2, 0.25],\n",
    "    'num_encoder_layers': [4, 5, 6], # they had 8 in Attention is all you need\n",
    "    'nhead': [4, 8],\n",
    "    'ffn_hidden_dim_factor': [2, 3 ,4]\n",
    "}\n",
    "N_SEARCH_ITERATIONS = 10 # number of random combinations to try\n",
    "\n",
    "\n",
    "# --- Device Setup ---\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'--- Running Experiment for_ {EMBEDDING_TYPE} ---')\n",
    "print(f'Using device: {DEVICE}')\n",
    "print(f'Embeddings Path: {H5_FILE_PATH}')\n",
    "print(f'Embeddings Dimensin: {EMBED_DIM}')\n",
    "print(f'Output Directory: {RUN_TYPE_DIR}')\n",
    "\n",
    "\n",
    "# --- SEEDING ---\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(RANDOM_SEED)\n",
    "\n",
    "# --- Creating Directories ---\n",
    "os.makedirs(RUN_TYPE_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(RUN_TYPE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Loading all protein keys (from hfd5 file)\n",
    "try:\n",
    "    with h5py.File(H5_FILE_PATH, 'r') as f:\n",
    "        if 'embeddings_folder' not in f: raise KeyError(\"Not found\")\n",
    "        all_protein_keys = list(f['embeddings_folder'].keys())\n",
    "        all_protein_keys.sort()\n",
    "        all_protein_keys = np.array(all_protein_keys)\n",
    "    print(f\"Loaded {len(all_protein_keys)} keys from {H5_FILE_PATH}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found\")\n",
    "    exit()\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"Error loading from HDF {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error loading keys; {e}\")\n",
    "    exit()\n",
    "    \n",
    "# Hyperparameter Search Initialization\n",
    "sampler = ParameterSampler(param_dist, n_iter=N_SEARCH_ITERATIONS, random_state=RANDOM_SEED)\n",
    "all_trial_results = []\n",
    "trial_num = 0\n",
    "\n",
    "print(f\"\\n--- Starting Hyperparameter Search ({N_SEARCH_ITERATIONS} trials) for {EMBEDDING_TYPE} ---\")\n",
    "\n",
    "for params in sampler:\n",
    "    trial_num += 1\n",
    "    print(f\"\\n----- Trial {trial_num}/{N_SEARCH_ITERATIONS} ({EMBEDDING_TYPE}) -----\")\n",
    "    print(f\"Parameters: {params}\")\n",
    "\n",
    "    # Extract params for this trial\n",
    "    LEARNING_RATE = params['learning_rate']\n",
    "    DROPOUT = params['dropout']\n",
    "    NUM_ENCODER_LAYERS = params['num_encoder_layers']\n",
    "    N_HEAD = params['nhead']\n",
    "    FFN_HIDDEN_DIM_FACTOR = params['ffn_hidden_dim_factor']\n",
    "    FFN_HIDDEN_DIM = int(EMBED_DIM * FFN_HIDDEN_DIM_FACTOR)\n",
    "\n",
    "    # Check nhead validity\n",
    "    if EMBED_DIM % N_HEAD != 0:\n",
    "        print(f\"Skipping trial: embed_dim ({EMBED_DIM}) not divisible by nhead ({N_HEAD}).\")\n",
    "        continue\n",
    "\n",
    "    # 3. K-Fold Cross-Validation Loop for this set of parameters\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(all_protein_keys)):\n",
    "        print(f\"\\n--- Fold {fold + 1}/{N_SPLITS} ---\")\n",
    "        set_seed(RANDOM_SEED + fold)\n",
    "\n",
    "        # Create distinct TensorBoard log directory for this fold/trial\n",
    "        # Group by trial first, then fold\n",
    "        fold_log_dir = os.path.join(TENSORBOARD_BASE_DIR, f'trial_{trial_num}', f'fold_{fold+1}')\n",
    "        writer = SummaryWriter(log_dir=fold_log_dir)\n",
    "\n",
    "        train_keys = all_protein_keys[train_idx]\n",
    "        val_keys = all_protein_keys[val_idx]\n",
    "\n",
    "        # Create datasets and dataloaders\n",
    "        train_dataset = Embedding_retriever(H5_FILE_PATH, protein_keys=list(train_keys))\n",
    "        val_dataset = Embedding_retriever(H5_FILE_PATH, protein_keys=list(val_keys))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=2, pin_memory=True if DEVICE == torch.device(\"cuda\") else False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2, pin_memory=True if DEVICE == torch.device(\"cuda\") else False)\n",
    "\n",
    "        # Calculate pos_weight\n",
    "        print(\"Calculating pos_weight...\")\n",
    "        num_pos, num_neg = 0, 0\n",
    "        # Safer iteration to calculate pos_weight\n",
    "        temp_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "        for batch in tqdm.tqdm(temp_loader, desc=\"Calculating pos_weight\", leave=False, ncols=80):\n",
    "            labels = batch['labels'] # Labels are already tensors\n",
    "            active_mask = (labels != -1)\n",
    "            active_labels = labels[active_mask].numpy() # Calculate on active labels\n",
    "            num_pos += np.sum(active_labels == 1)\n",
    "            num_neg += np.sum(active_labels == 0)\n",
    "        del temp_loader # Free memory\n",
    "\n",
    "        if num_pos == 0 or num_neg == 0:\n",
    "            print(f\"Warning: Fold {fold+1} - num_pos={num_pos}, num_neg={num_neg}. Using pos_weight=1.0\")\n",
    "            pos_weight = 1.0\n",
    "        else:\n",
    "            pos_weight = num_neg / num_pos\n",
    "        print(f\"Fold {fold+1} - pos_weight: {pos_weight:.2f}\")\n",
    "        pos_weight_tensor = torch.tensor([pos_weight], dtype=torch.float32).to(DEVICE)\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor) # Good for imbalanced data sets\n",
    "\n",
    "        # Instantiate NEW model and optimizer\n",
    "        model = EpitopeTransformer(\n",
    "            embed_dim=EMBED_DIM,\n",
    "            nhead=N_HEAD,\n",
    "            num_encoder_layers=NUM_ENCODER_LAYERS,\n",
    "            ffn_hidden_dim=FFN_HIDDEN_DIM,\n",
    "            dropout=DROPOUT\n",
    "        ).to(DEVICE)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        best_val_f1 = -1\n",
    "        best_fold_metrics = {}\n",
    "\n",
    "        # 4. Epoch Loop for the Fold\n",
    "        print(f\"Starting training for {N_EPOCHS} epochs...\")\n",
    "        for epoch in range(N_EPOCHS):\n",
    "            train_loss = train_epoch(model, train_loader, optimizer, criterion, DEVICE, epoch, writer)\n",
    "            print(f\"Epoch {epoch+1}/{N_EPOCHS} - Train Loss: {train_loss:.4f}\")\n",
    "            val_loss, precision, recall, f1, auc_roc, auc_pr, auc10 = evaluate(model, val_loader, criterion, DEVICE, epoch, writer)\n",
    "\n",
    "            if f1 > best_val_f1:\n",
    "                print(f\"Epoch {epoch+1} - Val F1 improved ({best_val_f1:.4f} -> {f1:.4f}). Saving model...\")\n",
    "                best_val_f1 = f1\n",
    "                best_fold_metrics = {\n",
    "                    'loss': val_loss, 'precision': precision, 'recall': recall,\n",
    "                    'f1': f1, 'auc_roc': auc_roc, 'auc_pr': auc_pr, 'epoch': epoch+1\n",
    "                }\n",
    "                # Save model to the type-specific directory\n",
    "                model_save_path = os.path.join(MODEL_SAVE_DIR, f'trial_{trial_num}_fold_{fold+1}_best.pth')\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "        print(f\"\\nBest Validation Metrics for Fold {fold + 1} (Epoch {best_fold_metrics.get('epoch', 'N/A')}):\")\n",
    "        print(best_fold_metrics)\n",
    "        if best_fold_metrics: # Only append if a best model was found\n",
    "             fold_results.append(best_fold_metrics)\n",
    "        else:\n",
    "             print(f\"Fold {fold+1} did not yield improving metrics.\")\n",
    "\n",
    "\n",
    "\n",
    "        writer.close()\n",
    "        del model, optimizer, train_loader, val_loader, train_dataset, val_dataset, criterion, pos_weight_tensor\n",
    "        gc.collect()\n",
    "        if DEVICE == torch.device(\"cuda\"): torch.cuda.empty_cache()\n",
    "    # --- End of Fold Loop ---\n",
    "\n",
    "\n",
    "    # --- Summarize Fold Results for the Current Trial ---\n",
    "    if fold_results:\n",
    "        # Calculate average metrics only on folds that produced results\n",
    "        avg_metrics = {key: np.mean([fold[key] for fold in fold_results if key != 'epoch'])\n",
    "                       for key in fold_results[0] if key != 'epoch'}\n",
    "        std_metrics = {key: np.std([fold[key] for fold in fold_results if key != 'epoch'])\n",
    "                       for key in fold_results[0] if key != 'epoch'}\n",
    "        print(f\"\\n----- Trial {trial_num} ({EMBEDDING_TYPE}) Cross-Validation Summary -----\")\n",
    "        print(\"Average Metrics across folds:\")\n",
    "        for key, value in avg_metrics.items():\n",
    "            print(f\"  Avg {key}: {value:.4f} (+/- {std_metrics[key]:.4f})\")\n",
    "        trial_summary = {'trial_num': trial_num, 'params': params, 'avg_metrics': avg_metrics, 'std_metrics': std_metrics, 'individual_fold_metrics': fold_results}\n",
    "    else:\n",
    "        print(f\"----- Trial {trial_num} ({EMBEDDING_TYPE}) had no valid fold results -----\")\n",
    "        trial_summary = {'trial_num': trial_num, 'params': params, 'avg_metrics': {}, 'std_metrics': {}, 'individual_fold_metrics': []}\n",
    "\n",
    "    all_trial_results.append(trial_summary)\n",
    "\n",
    "\n",
    "    # Save results incrementally\n",
    "    try:\n",
    "        with open(RESULTS_FILE, 'w') as f:\n",
    "            json.dump(all_trial_results, f, indent=4, default=lambda x: float(x) if isinstance(x, (np.float32, np.float64)) else x) # Handle numpy floats\n",
    "        print(f\"Trial {trial_num} results saved to {RESULTS_FILE}\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error saving results to {RESULTS_FILE}: {e}\")\n",
    "    except TypeError as e:\n",
    "        print(f\"Error serializing results to JSON: {e}. Check data types.\")\n",
    "\n",
    "# --- End of Trial Loop ---\n",
    "\n",
    "\n",
    "# --- Final Hyperparameter Search Summary ---\n",
    "print(f\"\\n--- Hyperparameter Search Complete for {EMBEDDING_TYPE} ---\")\n",
    "if all_trial_results:\n",
    "    # Filter out trials with no avg_metrics before finding max\n",
    "    valid_trials = [t for t in all_trial_results if t.get('avg_metrics')]\n",
    "    if valid_trials:\n",
    "        best_trial = max(valid_trials, key=lambda x: x.get('avg_metrics', {}).get('f1', -1))\n",
    "        print(\"\\nBest Trial Found:\")\n",
    "        print(f\"  Trial Number: {best_trial['trial_num']}\")\n",
    "        print(f\"  Parameters: {best_trial['params']}\")\n",
    "        print(f\"  Avg F1 Score: {best_trial.get('avg_metrics', {}).get('f1', 'N/A'):.4f}\")\n",
    "        print(f\"  Avg AUC-PR: {best_trial.get('avg_metrics', {}).get('auc_pr', 'N/A'):.4f}\")\n",
    "    else:\n",
    "        print(\"No trials yielded valid average metrics.\")\n",
    "\n",
    "    print(f\"\\nFull results saved in: {RESULTS_FILE}\")\n",
    "    print(f\"TensorBoard logs in: {TENSORBOARD_BASE_DIR}\")\n",
    "    print(f\"Best model checkpoints saved in: {MODEL_SAVE_DIR}\")\n",
    "else:\n",
    "    print(\"No successful trials were completed.\")\n",
    "\n",
    "print(\"\\nScript Finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
